{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cookbook -- OpenAI Recommendations Using Embeddings\n",
    "\n",
    "This cookbook integrates lastmile-eval into [this example cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb) from openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Set the following variables in your .env file:\n",
    "\n",
    "OPENAI_API_KEY=\\<your [openai api key](https://platform.openai.com/api-keys)\\>\n",
    "\n",
    "LASTMILE_API_TOKEN=\\<your [lastmile api token](https://lastmileai.dev/settings?page=tokens)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this cookbook\n",
    "%pip install pandas\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install lastmile-eval\n",
    "\n",
    "# For embeddings_utils\n",
    "%pip install matplotlib\n",
    "%pip install plotly\n",
    "%pip install scipy\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start RAG Debugger Server\n",
    "\n",
    "To start the server, open a terminal and run `rag-debug launch`\n",
    "\n",
    "Alternatively, run the next cell and stop the cell after the server port is shown in the output. The server will continue running in the background and will be stopped when the kernel stops or restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rag-debug launch\n",
    "\n",
    "# The server starts at the local port specified in the output. \n",
    "# Stop or restart the kernel to stop the RAG debugger server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lastmile_eval.rag.debugger.api.tracing import LastMileTracer\n",
    "from lastmile_eval.rag.debugger.tracing.sdk import get_lastmile_tracer\n",
    "\n",
    "tracer: LastMileTracer = get_lastmile_tracer(\n",
    "    tracer_name=\"embedding_recommendations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation using embeddings and nearest neighbor search\n",
    "Recommendations are widespread across the web.\n",
    "\n",
    "- 'Bought that item? Try these similar items.'\n",
    "- 'Enjoy that book? Try these similar titles.'\n",
    "- 'Not the help page you were looking for? Try these similar pages.'\n",
    "This notebook demonstrates how to use embeddings to find similar items to recommend. In particular, we use AG's corpus of news articles as our dataset.\n",
    "\n",
    "Our model will answer the question: given an article, what other articles are most similar to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from utils.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "Next, let's load the AG news data and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html)\n",
    "dataset_path = \"data/AG_news_samples.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "n_examples = 5\n",
    "df.head(n_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at those same examples, but not truncated by ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the title, description, and label of each example\n",
    "for idx, row in df.head(n_examples).iterrows():\n",
    "    print(\"\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Description: {row['description']}\")\n",
    "    print(f\"Label: {row['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build cache to save embeddings (DELETE cache file to re-create embeddings!)\n",
    "Before getting embeddings for these articles, let's set up a cache to save the embeddings we generate. In general, it's a good idea to save your embeddings so you can re-use them later. If you don't save them, you'll pay again each time you compute them again.\n",
    "\n",
    "The cache is a dictionary that maps tuples of `(text, model)` to an embedding, which is a list of floats. The cache is saved as a Python pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "embedding_cache_path = \"data/recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "@tracer.start_as_current_span(\"embedding_from_string\")\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it works by getting an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as an example, take the first description from the dataset\n",
    "example_string = df[\"description\"].values[0]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommend similar articles based on embeddings\n",
    "To find similar articles, let's follow a three-step plan:\n",
    "\n",
    "- Get the similarity embeddings of all the article descriptions\n",
    "- Calculate the distance between a source title and all other articles\n",
    "- Print out the other articles closest to the source title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lastmile_eval.rag.debugger.api import (\n",
    "    QueryReceived,\n",
    ")\n",
    "\n",
    "@tracer.start_as_current_span(\"print_recommendations_from_strings\")\n",
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    # Register the relevant params from the function\n",
    "    tracer.register_param(\"strings\", strings)\n",
    "    tracer.register_param(\"index_of_source_string\", index_of_source_string)\n",
    "    tracer.register_param(\"k_nearest_neighbors\", k_nearest_neighbors)\n",
    "    tracer.register_param(\"model\", model)\n",
    "\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "\n",
    "    # get distances between the source embedding and other embeddings (function from utils.embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    \n",
    "    # get indices of nearest neighbors (function from utils.utils.embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "\n",
    "    # Mark this query as QueryReceived event\n",
    "    tracer.mark_rag_query_trace_event(QueryReceived(query=query_string))\n",
    "\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k articles\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example recommendations\n",
    "Let's look for articles similar to first one, which was about Tony Blair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_descriptions = df[\"description\"].tolist()\n",
    "\n",
    "tony_blair_articles = print_recommendations_from_strings(\n",
    "    strings=article_descriptions,  # let's base similarity off of the article description\n",
    "    index_of_source_string=0,  # articles similar to the first one about Tony Blair\n",
    "    k_nearest_neighbors=5,  # 5 most similar articles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! 4 of the 5 recommendations explicitly mention Tony Blair and the fifth is an article from London about climate change, topics that might be often associated with Tony Blair.\n",
    "\n",
    "Let's see how our recommender does on the second example article about NVIDIA's new chipset with more security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipset_security_articles = print_recommendations_from_strings(\n",
    "    strings=article_descriptions,  # let's base similarity off of the article description\n",
    "    index_of_source_string=1,  # let's look at articles similar to the second one about a more secure chipset\n",
    "    k_nearest_neighbors=5,  # let's look at the 5 most similar articles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the printed distances, you can see that the #1 recommendation is much closer than all the others (0.11 vs 0.14+). And the #1 recommendation looks very similar to the starting article - it's another article from PC World about increasing computer security. Pretty good!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-dogfood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
