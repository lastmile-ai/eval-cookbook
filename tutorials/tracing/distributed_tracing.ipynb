{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbh9LVaVvwUz"
      },
      "source": [
        "# Distributed Tracing with LastMile Tracing SDK\n",
        "\n",
        "In this example notebook, we showcase how to implement distributed tracing using the LastMile Tracing SDK.\n",
        "\n",
        "## Notebook Outline\n",
        "* [Introduction](#intro)\n",
        "* [Setup](#setup)\n",
        "* [Step 1: Instrument server code](#step1)\n",
        "* [Step 2: Instrument client code](#step2)\n",
        "* [Step 3: View Trace Data in UI](#step3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"intro\"></a>\n",
        "# Introduction\n",
        "**Distributed tracing** allows you to track and analyze the flow of requests across multiple services or components in a distributed system.\n",
        "\n",
        "This example involves the client sending a request to a server to generate a riddle with `gpt-3.5-turbo`. The server uses OpenAI's `gpt-3.5-turbo` to generate the riddle and returns it to the client. The LastMile Tracing SDK is used to to instrument tracing and capture trace information."
      ],
      "metadata": {
        "id": "dgUE0NodwnuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"setup\"></a>\n",
        "\n",
        "# Setup\n",
        "\n",
        "To begin, we need to install lastmile-eval library and a couple other libraries for the example."
      ],
      "metadata": {
        "id": "dZsHsTimxR_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AjBExwI2vwU0",
        "outputId": "d4f48c32-56d7-4241-ae4f-37f1fb287245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lastmile-eval\n",
            "  Downloading lastmile_eval-0.0.51-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lastmile-eval) (2.31.0)\n",
            "Collecting python-dotenv (from lastmile-eval)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pydantic>=2.1 in /usr/local/lib/python3.10/dist-packages (from lastmile-eval) (2.7.1)\n",
            "Collecting result (from lastmile-eval)\n",
            "  Downloading result-0.16.1-py3-none-any.whl (11 kB)\n",
            "Collecting lastmile-utils (from lastmile-eval)\n",
            "  Downloading lastmile_utils-0.0.24-py3-none-any.whl (15 kB)\n",
            "Collecting llama-index (from lastmile-eval)\n",
            "  Downloading llama_index-0.10.39-py3-none-any.whl (6.8 kB)\n",
            "Collecting evaluate==0.4.1 (from lastmile-eval)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arize-phoenix-evals==0.5.0 (from lastmile-eval)\n",
            "  Downloading arize_phoenix_evals-0.5.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.1.2 (from lastmile-eval)\n",
            "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting instructor (from lastmile-eval)\n",
            "  Downloading instructor-1.3.2-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.0.0 (from lastmile-eval)\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score (from lastmile-eval)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opentelemetry-api (from lastmile-eval)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk (from lastmile-eval)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp (from lastmile-eval)\n",
            "  Downloading opentelemetry_exporter_otlp-1.24.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting opentelemetry-semantic-conventions (from lastmile-eval)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting openinference-semantic-conventions (from lastmile-eval)\n",
            "  Downloading openinference_semantic_conventions-0.1.6-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from arize-phoenix-evals==0.5.0->lastmile-eval) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix-evals==0.5.0->lastmile-eval) (4.11.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.4.1->lastmile-eval)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->lastmile-eval) (1.25.2)\n",
            "Collecting dill (from evaluate==0.4.1->lastmile-eval)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate==0.4.1->lastmile-eval)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate==0.4.1->lastmile-eval)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->lastmile-eval) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->lastmile-eval) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->lastmile-eval) (24.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->lastmile-eval)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->lastmile-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->lastmile-eval) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.2->lastmile-eval) (2024.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->lastmile-eval) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0.0->lastmile-eval) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.0.0->lastmile-eval)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->lastmile-eval) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.1->lastmile-eval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.1->lastmile-eval) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lastmile-eval) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lastmile-eval) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lastmile-eval) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lastmile-eval) (2024.2.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor->lastmile-eval) (3.9.5)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor->lastmile-eval) (0.16)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor->lastmile-eval) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor->lastmile-eval) (8.3.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor->lastmile-eval) (0.9.4)\n",
            "Collecting black==23.11.0 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading black-23.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from lastmile-utils->lastmile-eval) (5.2.0)\n",
            "Collecting flake8==6.1.0 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading flake8-6.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort==5.12.0 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylint==3.0.2 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading pylint-3.0.2-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.6/510.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyright==1.1.335 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading pyright-1.1.335-py3-none-any.whl (17 kB)\n",
            "Collecting pytest==7.4.3 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading pytest-7.4.3-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.1/325.1 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from lastmile-eval)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting result (from lastmile-eval)\n",
            "  Downloading result-0.16.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting autoflake==2.2.1 (from lastmile-utils->lastmile-eval)\n",
            "  Downloading autoflake-2.2.1-py3-none-any.whl (32 kB)\n",
            "Collecting pyflakes>=3.0.0 (from autoflake==2.2.1->lastmile-utils->lastmile-eval)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from autoflake==2.2.1->lastmile-utils->lastmile-eval) (2.0.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==23.11.0->lastmile-utils->lastmile-eval) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==23.11.0->lastmile-utils->lastmile-eval)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black==23.11.0->lastmile-utils->lastmile-eval)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==23.11.0->lastmile-utils->lastmile-eval) (4.2.2)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8==6.1.0->lastmile-utils->lastmile-eval)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8==6.1.0->lastmile-utils->lastmile-eval)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes>=3.0.0 (from autoflake==2.2.1->lastmile-utils->lastmile-eval)\n",
            "  Downloading pyflakes-3.1.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astroid<=3.1.0-dev0,>=3.0.1 (from pylint==3.0.2->lastmile-utils->lastmile-eval)\n",
            "  Downloading astroid-3.0.3-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/275.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tomlkit>=0.10.1 (from pylint==3.0.2->lastmile-utils->lastmile-eval)\n",
            "  Downloading tomlkit-0.12.5-py3-none-any.whl (37 kB)\n",
            "Collecting nodeenv>=1.6.0 (from pyright==1.1.335->lastmile-utils->lastmile-eval)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.3->lastmile-utils->lastmile-eval) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.3->lastmile-utils->lastmile-eval) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.3->lastmile-utils->lastmile-eval) (1.2.1)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_agent_openai-0.2.5-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.39 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_core-0.10.39.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_llms_openai-0.1.21-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index->lastmile-eval)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api->lastmile-eval)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api->lastmile-eval)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.24.0 (from opentelemetry-exporter-otlp->lastmile-eval)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.24.0 (from opentelemetry-exporter-otlp->lastmile-eval)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile-eval) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile-eval) (1.64.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile-eval)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile-eval)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile-eval) (3.20.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->lastmile-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score->lastmile-eval) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->lastmile-eval) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile-eval) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval) (0.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval) (6.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api->lastmile-eval) (1.14.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0.0->lastmile-eval)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->lastmile-eval)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api->lastmile-eval) (3.18.2)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval) (2.0.30)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval) (3.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval) (9.4.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile-eval) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile-eval)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile-eval)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index->lastmile-eval)\n",
            "  Downloading llama_parse-0.4.3-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score->lastmile-eval) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score->lastmile-eval) (2023.12.25)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->lastmile-eval) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->lastmile-eval) (2.16.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile-eval) (2.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->lastmile-eval) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=1.6.0->pyright==1.1.335->lastmile-utils->lastmile-eval) (67.7.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval) (3.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.39->llama-index->lastmile-eval)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=34975930f423b2bd5f570b5ae6acf6aaf5e52abf06d87d3b98866a3945750278\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: striprtf, dirtyjson, xxhash, tomlkit, result, python-dotenv, pytest, pypdf, pyflakes, pycodestyle, pathspec, opentelemetry-semantic-conventions, opentelemetry-proto, openinference-semantic-conventions, nodeenv, mypy-extensions, mccabe, marshmallow, isort, importlib-metadata, h11, dill, deprecated, astroid, typing-inspect, tiktoken, rouge-score, responses, pyright, pylint, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, multiprocess, httpcore, flake8, black, autoflake, opentelemetry-sdk, lastmile-utils, httpx, dataclasses-json, arize-phoenix-evals, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openai, llamaindex-py-client, datasets, opentelemetry-exporter-otlp, llama-index-legacy, llama-index-core, instructor, evaluate, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, lastmile-eval\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arize-phoenix-evals-0.5.0 astroid-3.0.3 autoflake-2.2.1 black-23.11.0 dataclasses-json-0.6.6 datasets-2.19.1 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 evaluate-0.4.1 flake8-6.1.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 importlib-metadata-7.0.0 instructor-1.3.2 isort-5.12.0 lastmile-eval-0.0.51 lastmile-utils-0.0.24 llama-index-0.10.39 llama-index-agent-openai-0.2.5 llama-index-cli-0.1.12 llama-index-core-0.10.39.post1 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.21 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.3 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mccabe-0.7.0 multiprocess-0.70.16 mypy-extensions-1.0.0 nodeenv-1.8.0 openai-1.30.3 openinference-semantic-conventions-0.1.6 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 pandas-2.1.2 pathspec-0.12.1 pycodestyle-2.11.1 pyflakes-3.1.0 pylint-3.0.2 pypdf-4.2.0 pyright-1.1.335 pytest-7.4.3 python-dotenv-1.0.0 responses-0.18.0 result-0.16.0 rouge-score-0.1.2 striprtf-0.0.26 tiktoken-0.7.0 tomlkit-0.12.5 typing-inspect-0.9.0 xxhash-3.4.1\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from multiprocess) (0.3.8)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install lastmile-eval --upgrade\n",
        "# fork of multiprocessing, uses dill instead of pickle.\n",
        "!pip install multiprocess\n",
        "!pip install flask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start this tutorial, we need the following tokens/keys:\n",
        "\n",
        "* LastMile AI API Token: Go to the [LastMile Settings page](https://lastmileai.dev/settings?page=tokens). You will need to first create a LastMile AI account.\n",
        "* OpenAI API Key: Go to [OpenAI API Keys page](https://platform.openai.com/account/api-keys) to create and access your OpenAI API Key.\n",
        "\n",
        "We're using Google Colab's Secret Manager to set our tokens in this notebook."
      ],
      "metadata": {
        "id": "XO-RslYuxt4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')\n",
        "os.environ['LASTMILE_API_TOKEN'] =  userdata.get('LASTMILE_API_TOKEN')"
      ],
      "metadata": {
        "id": "1R2Orscwx4-T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step1\"></a>\n",
        "# Step 1: Instrument Server Code\n",
        "In this step, we are starting a Flask server that expsoses an endpoint for generating riddles. The server uses a `LastMile Tracer` for distributed tracing (across the client).\n"
      ],
      "metadata": {
        "id": "wreDo5NjyRvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlLs3SGKvwU1",
        "outputId": "f53930d9-87ce-4391-face-976502a0d63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import multiprocess\n",
        "from flask import Flask, request\n",
        "from openai import OpenAI\n",
        "\n",
        "from lastmile_eval.rag.debugger.api import LastMileTracer\n",
        "from lastmile_eval.rag.debugger.tracing import get_lastmile_tracer\n",
        "\n",
        "\n",
        "def server():\n",
        "    # Instantiate LastMile Tracer\n",
        "    tracer: LastMileTracer = get_lastmile_tracer(\n",
        "        tracer_name=\"generate_riddle\",\n",
        "    )\n",
        "\n",
        "    app = Flask(__name__)\n",
        "\n",
        "    @app.route(\"/generate\")\n",
        "    def generate()-> str:\n",
        "        \"\"\"\n",
        "        Endpoint that generates a riddle using OpenAI's GPT-3.5-turbo model.\n",
        "        \"\"\"\n",
        "        span_context = request.headers.get(\"span\") # Expect a span to be passed to this endpoint\n",
        "\n",
        "        # Trace the span\n",
        "        with tracer.start_as_current_span(\"generate_endpoint\", context = span_context):\n",
        "            response = OpenAI().chat.completions.create(messages = [{\"role\": \"user\", \"content\":\"tell me a riddle\"}], model = \"gpt-3.5-turbo\")\n",
        "            riddle = response.choices[0].message.content\n",
        "            return json.dumps(riddle)\n",
        "\n",
        "    app.run(port=1234, debug=False)\n",
        "\n",
        "# Start Server in a Subprocess to avoid blocking execution of succeeding cells\n",
        "process = multiprocess.Process(target=server)\n",
        "process.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step2\"></a>\n",
        "# Step 2: Instrument Client Code\n",
        "In order distribute the trace context, we need to export the span context to a string and pass it as a header to the server."
      ],
      "metadata": {
        "id": "CX1ipalYzNtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Yvo8-EcTvwU1",
        "outputId": "9c053c18-dc96-4742-9a13-e4d0cb2c2301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: Sending request to subprocess server, with span context.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"I am taken from a mine, and shut up in a wooden case, from which I am never released, and yet I am used by almost every person. What am I?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import requests\n",
        "from opentelemetry import trace\n",
        "\n",
        "from lastmile_eval.rag.debugger.api import LastMileTracer\n",
        "from lastmile_eval.rag.debugger.tracing import export_span, get_lastmile_tracer\n",
        "\n",
        "# Instantiate Tracer2\n",
        "tracer2: LastMileTracer = get_lastmile_tracer(\n",
        "    tracer_name=\"generate_riddle\", # project name\n",
        ")\n",
        "\n",
        "@tracer2.start_as_current_span(\"client\")\n",
        "def client_say_riddle():\n",
        "    try:\n",
        "        print(\"Message: Sending request to subprocess server, with span context.\")\n",
        "\n",
        "        # Export Span\n",
        "        response = requests.get('http://127.0.0.1:1234/generate', headers={\"span\": export_span(trace.get_current_span())})\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "client_say_riddle()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step3\"></a>\n",
        "\n",
        "# Step 3: View Trace Data in UI\n",
        "Now we can view our distributed trace in the RAG Debugger UI!\n",
        "#### From your terminal:\n",
        "\n",
        "Export your LASTMILE_API_TOKEN\n",
        "\n",
        "```bash\n",
        "export LASTMILE_API_TOKEN=\"<your-api-token>\"\n",
        "```\n",
        "\n",
        "Run this CLI command to access the UI\n",
        "\n",
        "```bash\n",
        "rag-debug launch\n",
        "```\n",
        "Navigate to the 'Traces' Page where you see all the Traces listed including the Distributed Trace we set up in this example.\n",
        "\n",
        "<img width=\"973\" alt=\"Screen Shot 2024-05-28 at 1 28 58 AM\" src=\"https://github.com/lastmile-ai/aiconfig/assets/81494782/35393b82-4d1e-4346-afc3-e4f6d99cd765/\">\n",
        "\n",
        "Let's click into the Trace.\n",
        "\n",
        "<img width=\"973\" alt=\"Screen Shot 2024-05-28 at 1 30 29 AM\" src=\"https://github.com/lastmile-ai/aiconfig/assets/81494782/d25b9b96-2e30-4dfe-8245-076ae860c50c\"/>\n",
        "\n",
        "Here we can see that the server span with `generate_endpoint` has been successfully propagated to the client span with the Tracer. This shows that we're able to trace across multiple services or components in a distributed system."
      ],
      "metadata": {
        "id": "4wDtiRtR0GoT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSEK9Ony0nW0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}