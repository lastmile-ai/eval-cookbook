{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FDU2yIM42mf"
      },
      "source": [
        "# LastMile Instrumentor for LangChain\n",
        "\n",
        "\n",
        "In this notebook, we showcase how to use the **LastMile Tracing SDK** to auto-instrument tracing for a LangChain \"Plan-and-Execute\" agent. With tracing automatically setup, you can easily debug your application using LastMile's RAG Debugger.\n",
        "\n",
        "The LangChain \"Plan-and-Execute\" agent accomplishes an objective by first planning what to do and then executing the sub-tasks. LastMile autoinstrumentation is used to trace and monitor the execution of the agent.\n",
        "\n",
        "## Notebook Outline\n",
        "* [Step 1: Setup](#setup)\n",
        "* [Step 2: Configure the LastMile Instrumentor](#step2)\n",
        "* [Step 3: Define Tools for LangChain Agent](#step3)\n",
        "* [Step 4: Run example with LangChain Agent](#step4)\n",
        "* [Step 5: View Trace Data in RAG Debugger](#step5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV8hom_a5s5l"
      },
      "source": [
        "<a name=\"setup\"></a>\n",
        "# Step 1: Setup\n",
        "\n",
        "To begin, we need to install a few packages including langchain and lastmile-eval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WofBBh4j42mh",
        "outputId": "1a726577-f083-410d-8795-60df7c5c96db"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain_core\n",
        "!pip install langchain_experimental\n",
        "!pip install langchain_openai\n",
        "!pip install wikipedia\n",
        "!pip install numexpr\n",
        "!pip install lastmile_eval\n",
        "!pip install \"tracing-auto-instrumentation[langchain]\" --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M5EyhZm5yYa"
      },
      "source": [
        "Import the necessary libraries for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eae4CClw42mi"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_experimental.plan_and_execute import (\n",
        "    PlanAndExecute,\n",
        "    load_agent_executor,\n",
        "    load_chat_planner,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI, OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqAt8pH556R8"
      },
      "source": [
        "Before we start this tutorial, we need the following tokens/keys:\n",
        "\n",
        "* LastMile AI API Token: Go to the [LastMile Settings page](https://lastmileai.dev/settings?page=tokens). You will need to first create a LastMile AI account.\n",
        "* OpenAI API Key: Go to [OpenAI API Keys page](https://platform.openai.com/account/api-keys) to create and access your OpenAI API Key.\n",
        "\n",
        "We're using Google Colab's Secret Manager to set our tokens in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LSN4cIOR58Hy"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')\n",
        "os.environ['LASTMILE_API_TOKEN'] =  userdata.get('LASTMILE_API_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDosEMOC6Dd8"
      },
      "source": [
        "<a name=\"step2\"></a>\n",
        "\n",
        "# Step 2: Configure the LastMile Instrumentor\n",
        "\n",
        "Next, we create an instance of `LangChainInstrumentor` with a project name. The `instrument()` method is called to instrument the code for tracing and monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I2pL7WAp42mi"
      },
      "outputs": [],
      "source": [
        "from tracing_auto_instrumentation.langchain import LangChainInstrumentor\n",
        "\n",
        "# Create an instance of LangChainInstrumentor and instrument the code\n",
        "instrumentor = LangChainInstrumentor(project_name=\"Plan-and-Execute Example\")\n",
        "instrumentor.instrument()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wHo6mNK42mj"
      },
      "source": [
        "<a name=\"step3\"></a>\n",
        "\n",
        "# Step 3: Define Tools for Langchain Agent\n",
        "\n",
        "The tools that the agent will use for executing sub-tasks are defined. In this example, we have two tools:\n",
        "- \"Wikipedia\" tool: Uses the `WikipediaAPIWrapper` to look up information on Wikipedia.\n",
        "- \"Calculator\" tool: Uses the `LLMMathChain` to perform mathematical calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zxy2xTth42mj"
      },
      "outputs": [],
      "source": [
        "# Define the tools that the agent will use for executing sub-tasks\n",
        "wikipedia = WikipediaAPIWrapper()\n",
        "llm = OpenAI(temperature=0)\n",
        "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Wikipedia\",\n",
        "        func=wikipedia.run,\n",
        "        description=\"useful for when you need to look up information on Wikipedia\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"useful for when you need to perform mathematical calculations\",\n",
        "    ),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3LxpRFy42mj"
      },
      "source": [
        "<a name=\"step4\"></a>\n",
        "\n",
        "# Step 4: Run example with LangChain Agent\n",
        "\n",
        "Let's try an example with our LangChain agent. We will ask a simple question \"What is hte population of the capital city of the country where the Eiffel Tower is located? Calculate the square root of that number.\"\n",
        "\n",
        "The agent needs to look up the population (using Wikipedia) and then also make a calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lr53yAyt42mk",
        "outputId": "bfe995b4-e7e6-4cbc-ccbd-a8a1276aab50"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(temperature=0)\n",
        "planner = load_chat_planner(model)\n",
        "executor = load_agent_executor(model, tools, verbose=True)\n",
        "agent = PlanAndExecute(planner=planner, executor=executor)\n",
        "\n",
        "# ## Run Example\n",
        "\n",
        "# Run the agent with a sample question\n",
        "question = \"What is the population of the capital city of the country where the Eiffel Tower is located? Calculate the square root of that number.\"\n",
        "result = agent.run(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QcQczUG42mk",
        "outputId": "f3548f43-765d-4aed-e1ee-a27c8445fd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The square root of the population of Paris, which is approximately 2,102,650 residents, is 1450.0517232154168.\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p--LaCDV7Cn1"
      },
      "source": [
        "<a name=\"step5\"></a>\n",
        "\n",
        "# Step 5: View Trace Data in RAG Debugger\n",
        "Now we can view the trace data of our LangChain agent in a UI!\n",
        "#### From your terminal:\n",
        "\n",
        "Export your LASTMILE_API_TOKEN\n",
        "\n",
        "```bash\n",
        "export LASTMILE_API_TOKEN=\"<your-api-token>\"\n",
        "```\n",
        "\n",
        "Run this CLI command to access the UI\n",
        "\n",
        "```bash\n",
        "rag-debug launch\n",
        "```\n",
        "Navigate to the 'Traces' Page where you see all the Traces listed under this Project (top-right corner to choose Project).\n",
        "\n",
        "<img width=\"973\" alt=\"Screenshot 2024-05-28 at 12 06 53 PM\" src=\"https://github.com/lastmile-ai/aiconfig/assets/81494782/a2ad1630-dc62-43a6-8d81-cfa335fe8fb1\"/>\n",
        "\n",
        "\n",
        "Let's click into the Trace.\n",
        "\n",
        "<img width=\"973\" alt=\"Screenshot 2024-05-28 at 12 07 04 PM\" src=\"https://github.com/lastmile-ai/aiconfig/assets/81494782/01bb1693-a79c-40a6-962e-15446cbe03c6\"/>\n",
        "\n",
        "\n",
        "Here we can see all the spans auto-generated for us. This can help us debug and pinpoint issues in our application, especially if we add additional logging on top of the auto-instrumentor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtiM_XWY7ITk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "empty2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
