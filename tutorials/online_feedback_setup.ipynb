{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Feedback with LastMile Tracer\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates how to use the LastMile Tracer library to log online feedback for generated content using OpenAI's GPT-3.5-turbo model. It guides you through the process of setting up the LastMile Tracer, creating and managing traces and spans, and associating user feedback with specific traces for better analysis and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lastmile-eval --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 17:57:29,328 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-15 17:57:29,478 - https://lastmileai.dev:443 \"GET /api/evaluation_projects/list?name=my-tracer6 HTTP/1.1\" 200 345\n"
     ]
    }
   ],
   "source": [
    "# Setup Cell\n",
    "# Import necessary modules from the lastmile_eval package\n",
    "from lastmile_eval.rag.debugger.tracing import (\n",
    "    get_lastmile_tracer,\n",
    ")\n",
    "from lastmile_eval.rag.debugger.api import (\n",
    "    LastMileTracer)\n",
    "\n",
    "# Replace the lastmile_api_token with your actual token\n",
    "lastmile_api_token = \"enter token here!\"\n",
    "\n",
    "# Create a LastMileTracer instance with the specified project name and API token\n",
    "tracer: LastMileTracer = get_lastmile_tracer(\n",
    "    tracer_name=\"generate-riddle\", # project name\n",
    "    lastmile_api_token=lastmile_api_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logs feedback to the Project\n",
    "tracer.log_feedback(\"Rag debugger retrieves context nicely\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging Online Feedback Post Span and Trace Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lastmile_eval.rag.debugger.api import LastMileTracer\n",
    "from lastmile_eval.rag.debugger.tracing import get_lastmile_tracer\n",
    "from lastmile_eval.rag.debugger.tracing.sdk import get_span_id, get_trace_id\n",
    "import os\n",
    "from opentelemetry import trace\n",
    "import opentelemetry\n",
    "from openai import OpenAI\n",
    "tracer: LastMileTracer = get_lastmile_tracer(\n",
    "    tracer_name=\"generate_riddle7\", # project name\n",
    ")\n",
    "\n",
    "@tracer.start_as_current_span(\"generate_riddle\")\n",
    "def generate()-> str:\n",
    "    \"\"\"\n",
    "    Generates a riddle using OpenAI's GPT-3.5-turbo model.\n",
    "    If the OPENAI_API_KEY environment variable is not set, a default riddle is returned.\n",
    "    The generated riddle is returned as a string.\n",
    "    \"\"\"\n",
    "    riddle = \"\"\n",
    "    if os.environ.get(\"OPENAI_API_KEY\") is not None:\n",
    "        response = OpenAI().chat.completions.create(messages = [{\"role\": \"user\", \"content\":\"tell me a riddle\"}], model = \"gpt-3.5-turbo\")\n",
    "        riddle = response.choices[0].message.content or \"debugging me can be quite a trick.\"\n",
    "    else:\n",
    "        riddle = \"I'm a key that unlocks no doors, But fill me in, and power soars. In the realm where AI plays\"\n",
    "    # riddle = \"I'm a key that unlocks no doors, But fill me in, and power soars. In the realm where AI plays\"\n",
    "\n",
    "    # Store the span ID and trace ID associated with the generated riddle using the LastMileTracer's key-value store\n",
    "    # This allows us to retrieve the span and trace IDs later when logging feedback for the specific riddle\n",
    "    try:\n",
    "        # Store the span id and the trace ID with the generated riddle\n",
    "        tracer.store_trace_id(key=riddle, span_id=get_span_id(), trace_id= get_trace_id()) \n",
    "    except Exception as e:\n",
    "\n",
    "        print(f'Exception Occured when storing TraceID: {e}')\n",
    "    return riddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riddle = generate()\n",
    "\n",
    "# We stored the spanID in the previous step, so we can retrieve it using the riddle as the key\n",
    "trace_id, span_id = tracer.read_trace_id(key=riddle)\n",
    "\n",
    "tracer.log_feedback(span_id=span_id, trace_id=trace_id, feedback=\"The riddle was too easy.\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
