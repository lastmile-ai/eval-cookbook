{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f67904b-5fd6-443f-bf10-d49a69b25fcd",
      "metadata": {
        "id": "0f67904b-5fd6-443f-bf10-d49a69b25fcd",
        "tags": []
      },
      "source": [
        "# Evaluation Metrics with LastMile AI\n",
        "\n",
        "In this example notebook, we showcase how to measure the quality of your LLM applications (particularly RAG-based systems) with the **LastMile Evals** library.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BKKhmjGIKaYv",
      "metadata": {
        "id": "BKKhmjGIKaYv"
      },
      "source": [
        "## Notebook Outline\n",
        "* [Introduction](#intro)\n",
        "* [Setup](#setup)\n",
        "* [Part 1: RAG Evaluators](#rag_metrics)\n",
        "  * [p-faithful](#p-faithful)\n",
        "  * [Q/A on Retrieved Data](#qa-score)\n",
        "  * [AI vs Human (Ground Truth)](#ai-human-score)\n",
        "* [Part 2: Generic Evaluators](#generic-evaluators)\n",
        "   * [BLEU Score](#bleu)\n",
        "   * [ROUGE Score](#rouge)\n",
        "   * [Exact Match Score](#exact-match)\n",
        "   * [Summarization Score](#summarization)\n",
        "   * [Relevance Score](#relevance)\n",
        "   * [Toxicity Score](#toxicity)\n",
        "   * [Custom Semantic Similarity Score](#custom-semantic-similarity)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aebd935-07e0-44bb-a682-cf1d7b2a9b07",
      "metadata": {
        "id": "9aebd935-07e0-44bb-a682-cf1d7b2a9b07",
        "tags": []
      },
      "source": [
        "<a name=\"intro\"></a>\n",
        "# Introduction\n",
        "\n",
        "Evaluation is a crucial part of LLM development. To improve the performance of your LLM app, you must have a way to measure it. Evaluation metrics (aka evaluators) allow you to measure the quality of LLM-generated results. Evaluators can take in various inputs including the generated response, ground truth data, context, etc. and typically output a numeric score from 0 to 1.\n",
        "\n",
        "The **LastMile Evals library** provides a suite of evaluators for simple, fast, and accurate LLM-based evaluations. This notebook showcases how you can easily use the suite of evaluators to measure the quality of your LLM application."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad72f9c1-e35c-476d-94d8-ca9619d0cc08",
      "metadata": {
        "id": "ad72f9c1-e35c-476d-94d8-ca9619d0cc08",
        "tags": []
      },
      "source": [
        "<a name=\"setup\"></a>\n",
        "\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15284a54-35b3-4129-9a7a-57b7547bfaf4",
      "metadata": {
        "id": "15284a54-35b3-4129-9a7a-57b7547bfaf4",
        "tags": []
      },
      "source": [
        "To begin, we need to install the lastmile-eval library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1062e24-6177-459a-94e0-8e77b3e0859b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "d1062e24-6177-459a-94e0-8e77b3e0859b",
        "outputId": "9ee90780-bdc0-4972-a86d-8ddb8a4cd5b4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install lastmile-eval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51cb5df-9c98-44d8-8c69-1a0b784de3e3",
      "metadata": {
        "id": "f51cb5df-9c98-44d8-8c69-1a0b784de3e3"
      },
      "source": [
        "Now, we import all modules used in this tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09fbec4c-1864-4d76-9dbf-3d213ba58fc8",
      "metadata": {
        "id": "09fbec4c-1864-4d76-9dbf-3d213ba58fc8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from textwrap import dedent\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "from lastmile_eval.rag import get_rag_eval_scores\n",
        "import lastmile_eval.text as lm_eval_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c743f504-f28c-4802-89b6-ad152b74b0eb",
      "metadata": {
        "id": "c743f504-f28c-4802-89b6-ad152b74b0eb",
        "tags": []
      },
      "source": [
        "Before we start this tutorial, we need the following tokens/keys:\n",
        "\n",
        "* LastMile AI API Token: Go to the [LastMile Settings page](https://lastmileai.dev/settings?page=tokens). You will need to first create a LastMile AI account.\n",
        "* OpenAI API Key: Go to [OpenAI API Keys page](https://platform.openai.com/account/api-keys) to create and access your OpenAI API Key.\n",
        "\n",
        "We're using Google Colab's Secret Manager to set our tokens in this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "9lEr2ufSxGDs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "9lEr2ufSxGDs",
        "outputId": "49ea8c63-9fd5-4cfc-924e-d0f591de9437"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'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'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "userdata.get('LASTMILE_API_TOKEN')\n",
        "userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L1T5nuZmxvo5",
      "metadata": {
        "id": "L1T5nuZmxvo5"
      },
      "source": [
        "<a name=\"rag_metrics\"></a>\n",
        "#Part 1: RAG Evaluators\n",
        "RAG evaluators are helpful for measuring RAG systems. These metrics are specifically used to evaluate the quality of a model's response by assessing its relevance to the retrieved context, the original user query, and ground truth if available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bexoAs-_YMi",
      "metadata": {
        "id": "7bexoAs-_YMi"
      },
      "source": [
        "First, let's set our model-generated responses, retrieved contexts, and user queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "nsrtZe8A_a48",
      "metadata": {
        "id": "nsrtZe8A_a48"
      },
      "outputs": [],
      "source": [
        "model_response_texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"The fox is gold\",\n",
        "    ]\n",
        "retrieved_contexts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"The swift brown fox leaps over the lazy dog.\",\n",
        "    ]\n",
        "ground_truth_texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"The fox is yellow\",\n",
        "    ]\n",
        "user_queries = [\n",
        "        \"What does the animal do\",\n",
        "        \"Describe the fox\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9WdU-qvD-21",
      "metadata": {
        "id": "k9WdU-qvD-21"
      },
      "source": [
        "<a name=\"p-faithful\"></a>\n",
        "### p-faithful score\n",
        "The p-faithful score, computed by an LLM, evaluates the faithfulness of responses generated by a RAG system. This metric assesses how well the LLM's output aligns with the retrieved data, given a user query. By considering the triplet of information - user query, input data, and LLM's response - the p-faithful score ensures that the generated output is grounded in the provided context and accurately addresses the user's question. The score ranges from 0 to 1, with higher values indicating a more faithful response to the input data.\n",
        "\n",
        "Read more about p-faithful [here](https://blog.lastmileai.dev/harder-better-faster-stronger-llm-hallucination-detection-for-real-world-rag-part-i-949248f0ad94).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "dqK-LxSDFzKG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "dqK-LxSDFzKG",
        "outputId": "a06ced2d-d33d-42b6-efd3-f9d2c22b8155"
      },
      "outputs": [
        {
          "ename": "ReadTimeout",
          "evalue": "HTTPSConnectionPool(host='lastmileai.dev', port=443): Read timed out. (read timeout=60)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='lastmileai.dev', port=443): Read timed out. (read timeout=60)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a109c9da3cbd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mapi_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LASTMILE_API_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m result_dict = get_rag_eval_scores(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0muser_queries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mretrieved_contexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lastmile_eval/utils.py\u001b[0m in \u001b[0;36mget_rag_eval_scores\u001b[0;34m(queries, data, responses, api_token, config)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mauthentication_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RealAuthenticationConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     return _get_rag_eval_scores_helper(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthentication_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lastmile_eval/utils.py\u001b[0m in \u001b[0;36m_get_rag_eval_scores_helper\u001b[0;34m(queries, data, responses, authentication_config, config)\u001b[0m\n\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# TODO (rossdan): Add batch policies depending on premise + hypothesis sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     http_response = requests.Response = _call_eval_api(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lastmile_eval/utils.py\u001b[0m in \u001b[0;36m_call_eval_api\u001b[0;34m(queries, data, responses, authentication_config, endpoint_url, model_endpoint_id)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0mauthentication_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mcase\u001b[0m \u001b[0m_RealAuthenticationConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             return requests.post(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mendpoint_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Authorization\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"Bearer {api_token}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='lastmileai.dev', port=443): Read timed out. (read timeout=60)"
          ]
        }
      ],
      "source": [
        "api_token = userdata.get('LASTMILE_API_TOKEN')\n",
        "\n",
        "result_dict = get_rag_eval_scores(\n",
        "    user_queries,\n",
        "    retrieved_contexts,\n",
        "    model_response_texts,\n",
        "    api_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rxSxxh1g_t3f",
      "metadata": {
        "id": "rxSxxh1g_t3f"
      },
      "source": [
        "<a name=\"qa-score\"></a>\n",
        "### Q/A on Retrieved Data\n",
        "This metric evaluates whether a question was correctly answered by the system based on the retrieved data. The score is 1 if the answer is correct. The score is 0 if the question is not correctly or only partially answered by the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "z_354mVrAFAH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "aa36a46b05954df2a3dc104418b1db40",
            "22a81aa8be394bc9a231ba51dea0309f",
            "86bb28612ab44d538757671bc971a741",
            "33063783bca3494684f4c96ea612a7fa",
            "290fb84d64024ccbb8ee3627f5e88864",
            "345b7ca60d62493ea9af72367a54d3a8",
            "49f7d2e2bd1047539d492c73bb8f1b5b",
            "655926c3bab04491866e73b32f4d21f0",
            "1515eba9483a484a98af7053a0c7e52c",
            "53949346009247acb6688392f2ef9ec7",
            "288536aea0a64b919541f04903c236bc"
          ]
        },
        "id": "z_354mVrAFAH",
        "outputId": "7a62019d-259c-4eeb-af95-b4409ce5ee4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:phoenix.evals.executors:üêå!! If running llm_classify inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa36a46b05954df2a3dc104418b1db40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "qa = lm_eval_text.calculate_qa_score(model_response_texts, retrieved_contexts, user_queries, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d3cNVzv1ASPj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cNVzv1ASPj",
        "outputId": "87b36dbd-dd7c-4b9e-bb5f-25f930cc2ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-----------+\n",
            "| Example |             Model Response Text              |              Retrieved Context               |       User Query        | Q/A Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-----------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. | What does the animal do |    1.0    |\n",
            "|    2    |               The fox is gold                | The swift brown fox leaps over the lazy dog. |    Describe the fox     |    0.0    |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], retrieved_contexts[i], user_queries[i], qa[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Retrieved Context', 'User Query', 'Q/A Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mk0GRt6KBNsu",
      "metadata": {
        "id": "Mk0GRt6KBNsu"
      },
      "source": [
        "<a name=\"ai-human-score\"></a>\n",
        "### AI vs Human (Ground Truth)\n",
        "The AI vs Human Score, calculated by an LLM, compares AI-generated answers to a golden dataset of human-authored question-answer pairs. It assigns a score of 1 (correct) if the AI answer matches the human answer or captures its main idea, and 0 (incorrect) otherwise. This metric ensures that the AI system provides accurate and comprehensive responses, mirroring the quality of human-generated answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "w46GT3OhBNsu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "540be67272534cd8882a9f45d788fb6f",
            "f4cf1e00568a44478ce05a5d06f4ac02",
            "c8044ed30e7e49c889507eb048603e11",
            "cebc1db3aaf54d2aa31dd04881daf82b",
            "f50e489e00924e7eb9842696cd477165",
            "782e127d6a814f86aed6078252c303ac",
            "d9a9f2cc0dc24b0eaf08a6ec52be9718",
            "7b0f4f784f6746c0b626b24d44a2f6fb",
            "d11a4bba7dea4a7c9cf0e0b68bf3294f",
            "f1b8312298ab4dca91fef2cc81d953e5",
            "a3fb352e8b9b4afb8f56c83955dd7404"
          ]
        },
        "id": "w46GT3OhBNsu",
        "outputId": "49d05e28-fc9b-4f57-f869-777f95c259da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:phoenix.evals.executors:üêå!! If running llm_classify inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540be67272534cd8882a9f45d788fb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ai_vs_human = lm_eval_text.calculate_human_vs_ai_score(model_response_texts, ground_truth_texts, user_queries, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "4BsccSMcBNsv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BsccSMcBNsv",
        "outputId": "4f948c17-69a7-44ef-ad3e-4eb2ed247393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-------------------+\n",
            "| Example |             Model Response Text              |              Ground Truth Text               |       User Query        | AI vs Human Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. | What does the animal do |        1.0        |\n",
            "|    2    |               The fox is gold                |              The fox is yellow               |    Describe the fox     |        1.0        |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], ground_truth_texts[i], user_queries[i], ai_vs_human[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Ground Truth Text', 'User Query', 'AI vs Human Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71fddd07-ff4c-44d4-82af-64e2e416e853",
      "metadata": {
        "id": "71fddd07-ff4c-44d4-82af-64e2e416e853",
        "tags": []
      },
      "source": [
        "<a name=\"generic-evaluators\"></a>\n",
        "# Part 2: Generic Evaluators\n",
        "Generic evaluators are metrics used to assess the performance of NLP models (including LLMs) in tasks such as text generation, summarization, and translation often by comparing the model's output to reference data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c1a778-fd5a-4249-9704-580c52cacb10",
      "metadata": {
        "id": "e3c1a778-fd5a-4249-9704-580c52cacb10",
        "tags": []
      },
      "source": [
        "First, let's set our model-generated responses and human-labeled reference data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "oQlWuNNWybVx",
      "metadata": {
        "id": "oQlWuNNWybVx"
      },
      "outputs": [],
      "source": [
        "model_response_texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "    ]\n",
        "\n",
        "reference_texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"The swift brown fox leaps over the lazy dog.\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2llmbDh6ypHe",
      "metadata": {
        "id": "2llmbDh6ypHe"
      },
      "source": [
        "<a name=\"bleu\"></a>\n",
        "### BLEU Score\n",
        "BLEU (Bilingual Evaluation Understudy) score measures the similarity between the model-generated text response and the human labeled reference text. BLEU score ranges from 0 to 1, with higher *values* indicating better translation quality. A perfect translation would have a BLEU score of 1, while a completely incorrect translation would have a BLEU score of 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "O7PK6LJAzZlE",
      "metadata": {
        "id": "O7PK6LJAzZlE"
      },
      "outputs": [],
      "source": [
        "bleu = lm_eval_text.calculate_bleu_score(model_response_texts, reference_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9ZtcYyAmzBxv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZtcYyAmzBxv",
        "outputId": "b4022ddd-fe81-48bf-f6a9-6e403cd4e965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n",
            "| Example |             Model Response Text              |         Human Labeled Reference Text         |     BLEU Score     |\n",
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |        1.0         |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. | 0.4671379777282001 |\n",
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], bleu[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Human Labeled Reference Text', 'BLEU Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LeSPFq9Zy1AG",
      "metadata": {
        "id": "LeSPFq9Zy1AG"
      },
      "source": [
        "<a name=\"rouge\"></a>\n",
        "### ROUGE Score\n",
        "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score measures the similarity between a machine-generated summary and a human-created reference summaries. ROUGE score ranges from 0 to 1, with higher values indicating better summarization quality. A perfect summary would have a ROUGE score of 1, meaning it captures all the important information from the reference summaries, while a completely irrelevant summary would have a ROUGE score of 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9lv3ux1ay2lu",
      "metadata": {
        "id": "9lv3ux1ay2lu"
      },
      "outputs": [],
      "source": [
        "rouge1 = lm_eval_text.calculate_rouge1_score(model_response_texts, reference_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "BcKUGD-Q3AuM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcKUGD-Q3AuM",
        "outputId": "82342cab-fcfb-4af8-c236-50e3d257ba4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n",
            "| Example |             Model Response Text              |         Human Labeled Reference Text         |    ROUGE Score     |\n",
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |        1.0         |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. | 0.7777777777777778 |\n",
            "+---------+----------------------------------------------+----------------------------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], rouge1[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Human Labeled Reference Text', 'ROUGE Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TWB4Iqvg3I7j",
      "metadata": {
        "id": "TWB4Iqvg3I7j"
      },
      "source": [
        "<a name=\"exact-match\"></a>\n",
        "\n",
        "### Exact Match Score\n",
        "Exact match is a binary metric where a given model-generated text receives an exact match score of 1 if it is identical to its reference string, and 0 otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "YMGhxgI83IVN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b793b392388640bbbd3b8f66c9726210",
            "2c9c694937fd4db5a3341069708bd3f5",
            "5f228de59be04f4bbb0ef98257e190d6",
            "960b130667e141c0867d7aedb7e9babd",
            "365ab52b22ea488f98b094e3ccc63f49",
            "3f397729c9664d05987efb60bc00995c",
            "ad0b4083313f4985a2cf0a982bb3c789",
            "a95e84c6c53249e08bf2271a73d457d6",
            "680d58bc85094e938f708534cf77dd63",
            "0ab4cdc9cde2487bb6fc367c12d47027",
            "09e99797f9a54435b0099f53e1beaa5f"
          ]
        },
        "id": "YMGhxgI83IVN",
        "outputId": "86cda8eb-b348-4763-8f89-56ea562556cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b793b392388640bbbd3b8f66c9726210",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "exact_match = lm_eval_text.calculate_exact_match_score(model_response_texts, reference_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "T-7wreb43Gbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-7wreb43Gbe",
        "outputId": "ee54f86c-d174-4d54-89cd-f4b2caab7f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+-------------------+\n",
            "| Example |             Model Response Text              |                Reference Text                | Exact Match Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |        1.0        |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. |        0.0        |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], exact_match[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Reference Text', 'Exact Match Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sY19Ybpu5RKC",
      "metadata": {
        "id": "sY19Ybpu5RKC"
      },
      "source": [
        "<a name=\"summarization\"></a>\n",
        "### Summarization Score\n",
        "The Summarization Score, calculated by an LLM like GPT-3.5, evaluates the quality of a generated summary. It measures how well the summary captures the essential information from the original document. The score uses the default [Summarization Prompt Template from Phoenix Arize](https://docs.arize.com/phoenix/evaluation/how-to-evals/running-pre-tested-evals/summarization-eval) and ranges from 0 to 1. Higher values indicate better summarization performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "eEeHW8yY5zS8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "6ca9f951ccab48e594341136676778ea",
            "e9d3077e1da74d87ae049ddbd5608254",
            "6f07c00e35b6487199a3e640ef7b2421",
            "9d8374c943c94710938eff2f57239819",
            "f10b1dff25924d7e83a8523e3223f6cc",
            "b64d1b507f7a4ce7baba58b44d678b0b",
            "702f18ad66ea4e9ebdfcadadd742e5a0",
            "b90db0a9d85946dfb7913ce865fce774",
            "df46518eb307430fb2792b75a49bf2c8",
            "0cc69d36a1eb4dabaec047bf423e3321",
            "be1c6f65f1bf4eb5b53bc5c9e5919ffc"
          ]
        },
        "id": "eEeHW8yY5zS8",
        "outputId": "78485e7a-ea20-42f8-ad18-3227319db677"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:phoenix.evals.executors:üêå!! If running llm_classify inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ca9f951ccab48e594341136676778ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')\n",
        "summarization = lm_eval_text.calculate_summarization_score(model_response_texts, reference_texts, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "VdmdpkyX7UPb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdmdpkyX7UPb",
        "outputId": "d3bccad5-d0c9-4436-c5d5-58875d03e03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+---------------------+\n",
            "| Example |             Model Response Text              |                Reference Text                | Summarization Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+---------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |         1.0         |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. |         0.0         |\n",
            "+---------+----------------------------------------------+----------------------------------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], summarization[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Reference Text', 'Summarization Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YiyY3anpJGk_",
      "metadata": {
        "id": "YiyY3anpJGk_"
      },
      "source": [
        "<a name=\"relevance\"></a>\n",
        "### Relevance Score\n",
        "The Relevance Score, computed by an LLM, measures how pertinent an AI-generated response is to a given reference. It assigns a float score between 0 and 1 to each input-reference pair, with 1 indicating high relevance and 0 indicating irrelevance. This metric ensures that the AI system generates responses that are on-topic and aligned with the desired context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "lYMk3a6oLKiR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "d1c3c7ac201d40daba2de70efb0be315",
            "bc7d1b163f5c4f918849abbb81089ecc",
            "8dc3e55c710240948ce4decf4484748e",
            "b1d37e47419d45b9a68b34241b43473c",
            "7b463682a20b4c0aa15bc013a385d435",
            "2d4bc0a33f364eb7ad59323902184ec6",
            "5a21a37d6bda48da934faf2c6a8447e7",
            "4254b60a1e164191aae3b3a12cf1df78",
            "ae053eb903534c6888f02c8891bf3cbd",
            "de63f103215541d89a581165ca9a47d5",
            "0b9c5f57f27e4ac5b5ffec0fc267b1f4"
          ]
        },
        "id": "lYMk3a6oLKiR",
        "outputId": "99b43214-1150-4e54-bae7-ff25b9cb983a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:phoenix.evals.executors:üêå!! If running llm_classify inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1c3c7ac201d40daba2de70efb0be315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "relevance = lm_eval_text.calculate_relevance_score(model_response_texts, reference_texts, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "2SqVaCCaLSVB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SqVaCCaLSVB",
        "outputId": "68dd25c8-44fb-4ba6-d801-f72257f43706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+-----------------+\n",
            "| Example |             Model Response Text              |                Reference Text                | Relevance Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-----------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |       1.0       |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. |       1.0       |\n",
            "+---------+----------------------------------------------+----------------------------------------------+-----------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], relevance[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Reference Text', 'Relevance Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CN90A7FhGlIW",
      "metadata": {
        "id": "CN90A7FhGlIW"
      },
      "source": [
        "<a name=\"toxicity\"></a>\n",
        "### Toxicity Score\n",
        "The Toxicity Score, determined by an LLM, assesses whether an AI-generated response contains toxic content, such as hateful statements, demeaning language, inappropriate words, or threats of violence. The LLM assigns a binary score of 1 (toxic) if the response meets the definition of toxicity, and 0 (non-toxic) if the response is free from any words, sentiments, or meanings that could be considered toxic. This score helps ensure that the AI system generates safe and respectful responses, avoiding the production of harmful or offensive content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "LFl7e8QqHB_n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "f4a9603437934734be73cc0834f8235e",
            "79c2c3caec23477396943c7b46b773bb",
            "b39cc8651a6641bf9c392c8464c9ebad",
            "68707bd7cf524e83b0675fb5f9432fcb",
            "07a991ac8182441dafefa2310501d94d",
            "cc029e0d16af4781b31a9fd7bd1d9d31",
            "8b7cf7bf3ccd4d9682cd82a2b33bee49",
            "e4cf5ef4016749af9bb5be6981bccd13",
            "989a1258fe844550bac529e5d9183955",
            "35b8e00e0078479096e06e2cffef9b8f",
            "22372ddda1eb4c4198fd90d1cdea2597"
          ]
        },
        "id": "LFl7e8QqHB_n",
        "outputId": "11772c4b-d88b-4f7d-e65c-6a29d7b363a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:phoenix.evals.executors:üêå!! If running llm_classify inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4a9603437934734be73cc0834f8235e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llm_classify |          | 0/2 (0.0%) | ‚è≥ 00:00<? | ?it/s"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "texts_to_evaluate = [\"I am happy\", \"I am threatening violence\",]\n",
        "\n",
        "toxicity = lm_eval_text.calculate_toxicity_score(texts_to_evaluate, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "Hews9_XBHMC5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hews9_XBHMC5",
        "outputId": "02c627ae-1c90-4848-b422-dce051a67258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------------------------+----------------+\n",
            "| Example |     Text to Evaluate      | Toxicity Score |\n",
            "+---------+---------------------------+----------------+\n",
            "|    1    |        I am happy         |      0.0       |\n",
            "|    2    | I am threatening violence |      1.0       |\n",
            "+---------+---------------------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(texts_to_evaluate)):\n",
        "    data.append([i+1, texts_to_evaluate[i], toxicity[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Text to Evaluate', 'Toxicity Score'], tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y_l2mVlE70i2",
      "metadata": {
        "id": "Y_l2mVlE70i2"
      },
      "source": [
        "<a name=\"custom-semantic-similarity\"></a>\n",
        "### Custom Semantic Similarity Score\n",
        "The Custom Semantic Similarity Score, computed by an LLM like GPT-3.5, measures the semantic similarity between a generated text and a reference text. This score uses a customizable prompt template (default from Phoenix Arize is used in this notebook) that allows you to define the specific criteria for evaluating similarity. The LLM assigns a score between 0 and 1 to each pair of texts, with higher values indicating greater semantic similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "MrFsk5cA7u1t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrFsk5cA7u1t",
        "outputId": "570b3abd-6b73-48b0-cc7b-6923a86dade5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')\n",
        "custom_semantic_similarity = lm_eval_text.calculate_custom_llm_metric_example_semantic_similarity(model_response_texts, reference_texts, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "m-RUA3Bf8zPh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-RUA3Bf8zPh",
        "outputId": "b194bc08-4a99-42b5-b711-413f3ffe4948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------------------------------------+----------------------------------------------+----------------------------------+\n",
            "| Example |             Model Response Text              |                Reference Text                | Custom Semantic Similarity Score |\n",
            "+---------+----------------------------------------------+----------------------------------------------+----------------------------------+\n",
            "|    1    | The quick brown fox jumps over the lazy dog. | The quick brown fox jumps over the lazy dog. |               1.0                |\n",
            "|    2    | The quick brown fox jumps over the lazy dog. | The swift brown fox leaps over the lazy dog. |               0.7                |\n",
            "+---------+----------------------------------------------+----------------------------------------------+----------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print results in a nicely formatted table\n",
        "data = []\n",
        "for i in range(len(model_response_texts)):\n",
        "    data.append([i+1, model_response_texts[i], reference_texts[i], custom_semantic_similarity[i]])  # Here i+1 will serve as the example number.\n",
        "\n",
        "print(tabulate(data, headers=['Example', 'Model Response Text', 'Reference Text', 'Custom Semantic Similarity Score'], tablefmt='pretty'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07a991ac8182441dafefa2310501d94d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e99797f9a54435b0099f53e1beaa5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ab4cdc9cde2487bb6fc367c12d47027": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9c5f57f27e4ac5b5ffec0fc267b1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cc69d36a1eb4dabaec047bf423e3321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1515eba9483a484a98af7053a0c7e52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22372ddda1eb4c4198fd90d1cdea2597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a81aa8be394bc9a231ba51dea0309f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345b7ca60d62493ea9af72367a54d3a8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49f7d2e2bd1047539d492c73bb8f1b5b",
            "value": "llm_classify‚Äá"
          }
        },
        "288536aea0a64b919541f04903c236bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290fb84d64024ccbb8ee3627f5e88864": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9c694937fd4db5a3341069708bd3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f397729c9664d05987efb60bc00995c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad0b4083313f4985a2cf0a982bb3c789",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá100%"
          }
        },
        "2d4bc0a33f364eb7ad59323902184ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33063783bca3494684f4c96ea612a7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53949346009247acb6688392f2ef9ec7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_288536aea0a64b919541f04903c236bc",
            "value": "‚Äá2/2‚Äá(100.0%)‚Äá|‚Äá‚è≥‚Äá00:01&lt;00:00‚Äá|‚Äá‚Äá1.03it/s"
          }
        },
        "345b7ca60d62493ea9af72367a54d3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b8e00e0078479096e06e2cffef9b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365ab52b22ea488f98b094e3ccc63f49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f397729c9664d05987efb60bc00995c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4254b60a1e164191aae3b3a12cf1df78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f7d2e2bd1047539d492c73bb8f1b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53949346009247acb6688392f2ef9ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540be67272534cd8882a9f45d788fb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4cf1e00568a44478ce05a5d06f4ac02",
              "IPY_MODEL_c8044ed30e7e49c889507eb048603e11",
              "IPY_MODEL_cebc1db3aaf54d2aa31dd04881daf82b"
            ],
            "layout": "IPY_MODEL_f50e489e00924e7eb9842696cd477165"
          }
        },
        "5a21a37d6bda48da934faf2c6a8447e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f228de59be04f4bbb0ef98257e190d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a95e84c6c53249e08bf2271a73d457d6",
            "max": 5669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_680d58bc85094e938f708534cf77dd63",
            "value": 5669
          }
        },
        "655926c3bab04491866e73b32f4d21f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680d58bc85094e938f708534cf77dd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68707bd7cf524e83b0675fb5f9432fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b8e00e0078479096e06e2cffef9b8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_22372ddda1eb4c4198fd90d1cdea2597",
            "value": "‚Äá2/2‚Äá(100.0%)‚Äá|‚Äá‚è≥‚Äá00:01&lt;00:00‚Äá|‚Äá‚Äá1.14it/s"
          }
        },
        "6ca9f951ccab48e594341136676778ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9d3077e1da74d87ae049ddbd5608254",
              "IPY_MODEL_6f07c00e35b6487199a3e640ef7b2421",
              "IPY_MODEL_9d8374c943c94710938eff2f57239819"
            ],
            "layout": "IPY_MODEL_f10b1dff25924d7e83a8523e3223f6cc"
          }
        },
        "6f07c00e35b6487199a3e640ef7b2421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90db0a9d85946dfb7913ce865fce774",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df46518eb307430fb2792b75a49bf2c8",
            "value": 2
          }
        },
        "702f18ad66ea4e9ebdfcadadd742e5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782e127d6a814f86aed6078252c303ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c2c3caec23477396943c7b46b773bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc029e0d16af4781b31a9fd7bd1d9d31",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8b7cf7bf3ccd4d9682cd82a2b33bee49",
            "value": "llm_classify‚Äá"
          }
        },
        "7b0f4f784f6746c0b626b24d44a2f6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b463682a20b4c0aa15bc013a385d435": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bb28612ab44d538757671bc971a741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655926c3bab04491866e73b32f4d21f0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1515eba9483a484a98af7053a0c7e52c",
            "value": 2
          }
        },
        "8b7cf7bf3ccd4d9682cd82a2b33bee49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc3e55c710240948ce4decf4484748e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4254b60a1e164191aae3b3a12cf1df78",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae053eb903534c6888f02c8891bf3cbd",
            "value": 2
          }
        },
        "960b130667e141c0867d7aedb7e9babd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab4cdc9cde2487bb6fc367c12d47027",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_09e99797f9a54435b0099f53e1beaa5f",
            "value": "‚Äá5.67k/5.67k‚Äá[00:00&lt;00:00,‚Äá244kB/s]"
          }
        },
        "989a1258fe844550bac529e5d9183955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8374c943c94710938eff2f57239819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc69d36a1eb4dabaec047bf423e3321",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_be1c6f65f1bf4eb5b53bc5c9e5919ffc",
            "value": "‚Äá2/2‚Äá(100.0%)‚Äá|‚Äá‚è≥‚Äá31:35&lt;00:00‚Äá|‚Äá‚Äá1.56it/s"
          }
        },
        "a3fb352e8b9b4afb8f56c83955dd7404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a95e84c6c53249e08bf2271a73d457d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa36a46b05954df2a3dc104418b1db40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22a81aa8be394bc9a231ba51dea0309f",
              "IPY_MODEL_86bb28612ab44d538757671bc971a741",
              "IPY_MODEL_33063783bca3494684f4c96ea612a7fa"
            ],
            "layout": "IPY_MODEL_290fb84d64024ccbb8ee3627f5e88864"
          }
        },
        "ad0b4083313f4985a2cf0a982bb3c789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae053eb903534c6888f02c8891bf3cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1d37e47419d45b9a68b34241b43473c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de63f103215541d89a581165ca9a47d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0b9c5f57f27e4ac5b5ffec0fc267b1f4",
            "value": "‚Äá2/2‚Äá(100.0%)‚Äá|‚Äá‚è≥‚Äá00:01&lt;00:00‚Äá|‚Äá‚Äá1.30it/s"
          }
        },
        "b39cc8651a6641bf9c392c8464c9ebad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4cf5ef4016749af9bb5be6981bccd13",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_989a1258fe844550bac529e5d9183955",
            "value": 2
          }
        },
        "b64d1b507f7a4ce7baba58b44d678b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b793b392388640bbbd3b8f66c9726210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c9c694937fd4db5a3341069708bd3f5",
              "IPY_MODEL_5f228de59be04f4bbb0ef98257e190d6",
              "IPY_MODEL_960b130667e141c0867d7aedb7e9babd"
            ],
            "layout": "IPY_MODEL_365ab52b22ea488f98b094e3ccc63f49"
          }
        },
        "b90db0a9d85946dfb7913ce865fce774": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7d1b163f5c4f918849abbb81089ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4bc0a33f364eb7ad59323902184ec6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5a21a37d6bda48da934faf2c6a8447e7",
            "value": "llm_classify‚Äá"
          }
        },
        "be1c6f65f1bf4eb5b53bc5c9e5919ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8044ed30e7e49c889507eb048603e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0f4f784f6746c0b626b24d44a2f6fb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d11a4bba7dea4a7c9cf0e0b68bf3294f",
            "value": 2
          }
        },
        "cc029e0d16af4781b31a9fd7bd1d9d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cebc1db3aaf54d2aa31dd04881daf82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b8312298ab4dca91fef2cc81d953e5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3fb352e8b9b4afb8f56c83955dd7404",
            "value": "‚Äá2/2‚Äá(100.0%)‚Äá|‚Äá‚è≥‚Äá19:09&lt;00:00‚Äá|‚Äá‚Äá1.35it/s"
          }
        },
        "d11a4bba7dea4a7c9cf0e0b68bf3294f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1c3c7ac201d40daba2de70efb0be315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc7d1b163f5c4f918849abbb81089ecc",
              "IPY_MODEL_8dc3e55c710240948ce4decf4484748e",
              "IPY_MODEL_b1d37e47419d45b9a68b34241b43473c"
            ],
            "layout": "IPY_MODEL_7b463682a20b4c0aa15bc013a385d435"
          }
        },
        "d9a9f2cc0dc24b0eaf08a6ec52be9718": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de63f103215541d89a581165ca9a47d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df46518eb307430fb2792b75a49bf2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4cf5ef4016749af9bb5be6981bccd13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d3077e1da74d87ae049ddbd5608254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64d1b507f7a4ce7baba58b44d678b0b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_702f18ad66ea4e9ebdfcadadd742e5a0",
            "value": "llm_classify‚Äá"
          }
        },
        "f10b1dff25924d7e83a8523e3223f6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b8312298ab4dca91fef2cc81d953e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a9603437934734be73cc0834f8235e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79c2c3caec23477396943c7b46b773bb",
              "IPY_MODEL_b39cc8651a6641bf9c392c8464c9ebad",
              "IPY_MODEL_68707bd7cf524e83b0675fb5f9432fcb"
            ],
            "layout": "IPY_MODEL_07a991ac8182441dafefa2310501d94d"
          }
        },
        "f4cf1e00568a44478ce05a5d06f4ac02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782e127d6a814f86aed6078252c303ac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d9a9f2cc0dc24b0eaf08a6ec52be9718",
            "value": "llm_classify‚Äá"
          }
        },
        "f50e489e00924e7eb9842696cd477165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
