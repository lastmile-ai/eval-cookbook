{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Guide to Using the LastMile Instrumentor for LlamaIndex\n",
                "This guide will walk you through the process of using the LastMile Instrumentor for LlamaIndex. The LastMile Instrumentor is a powerful tool that allows you to trace and debug your LlamaIndex applications, providing valuable insights into their performance and behavior.\n",
                "\n",
                "\n",
                "\n",
                "Prerequisites\n",
                "Before we get started, make sure you have the following prerequisites installed:\n",
                "\n",
                "Python 3.x\n",
                "LlamaIndex\n",
                "OpenAI API key\n",
                "\n",
                "To install the required dependencies, run the first  cell"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install llama-index-embeddings-openai\n",
                "!pip install llama-index-embeddings-openai --upgrade\n",
                "\n",
                "%pip install -q html2text llama-index pandas pyarrow tqdm\n",
                "%pip install -q llama-index-readers-web\n",
                "%pip install -q llama-index-callbacks-openinference\n",
                "!pip install openai --upgrade"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 1: Import Required Libraries\n",
                "\n",
                "First, let's import the necessary libraries for our project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "import dotenv\n",
                "import llama_index.core\n",
                "from lastmile_eval.rag.debugger.tracing.auto_instrumentation import \\\n",
                "    LlamaIndexCallbackHandler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Configure the LastMile Instrumentor\n",
                "\n",
                "Next, we need to configure the LastMile Instrumentor by setting the global handler for LlamaIndex."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 16:20:07,373 - Overriding of current TracerProvider is not allowed\n",
                        "2024-05-06 16:20:07,396 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
                        "2024-05-06 16:20:07,478 - https://lastmileai.dev:443 \"GET /api/evaluation_projects/list?name=my-project HTTP/1.1\" 200 325\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "OpenAI API key configured\n"
                    ]
                }
            ],
            "source": [
                "import llama_index.core\n",
                "\n",
                "from lastmile_eval.rag.debugger.tracing.auto_instrumentation import (\n",
                "    LlamaIndexCallbackHandler,\n",
                ")\n",
                "llama_index.core.global_handler = LlamaIndexCallbackHandler(\n",
                "    project_name=\"LlamaIndex Paul Graham QA\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 3: Set Up OpenAI API Key"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dotenv.load_dotenv()\n",
                "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass(\n",
                "        \"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\"\n",
                "    )\n",
                "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
                "print(\"OpenAI API key configured\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 4: Load and Process Documents\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 16:20:12,776 - Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
                        "2024-05-06 16:20:12,866 - https://raw.githubusercontent.com:443 \"GET /run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt HTTP/1.1\" 200 28419\n"
                    ]
                }
            ],
            "source": [
                "from llama_index.core import VectorStoreIndex\n",
                "from llama_index.core.node_parser import SentenceSplitter\n",
                "from llama_index.readers.web import SimpleWebPageReader\n",
                "\n",
                "documents = SimpleWebPageReader().load_data(\n",
                "    [\n",
                "        \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\n",
                "    ]\n",
                ")\n",
                "\n",
                "parser = SentenceSplitter()\n",
                "nodes = parser.get_nodes_from_documents(documents)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 5: Create an Index and Query Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index.embeddings.openai.base import OpenAIEmbedding\n",
                "\n",
                "index = VectorStoreIndex.from_documents(documents)\n",
                "query_engine = index.as_query_engine()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 6: Query the Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_characters_per_line = 80\n",
                "queries = [\n",
                "    \"What did Paul Graham do growing up?\",\n",
                "    \"When and how did Paul Graham's mother die?\",\n",
                "    \"What, in Paul Graham's opinion, is the most distinctive thing about YC?\",\n",
                "    \"When and how did Paul Graham meet Jessica Livingston?\",\n",
                "    \"What is Bel, and when and where was it written?\",\n",
                "]\n",
                "for query in queries:\n",
                "    response = query_engine.query(query)\n",
                "    print(\"Query\")\n",
                "    print(\"=====\")\n",
                "    print(textwrap.fill(query, max_characters_per_line))\n",
                "    print()\n",
                "    print(\"Response\")\n",
                "    print(\"========\")\n",
                "    print(textwrap.fill(str(response), max_characters_per_line))\n",
                "    print()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
